{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1: LiDAR Clustering\n",
    "\n",
    "\n",
    "\n",
    "## Índice\n",
    "\n",
    "1. Integrantes del equipo\n",
    "\n",
    "2. Librerías\n",
    "\n",
    "3. Carga de Datos <br>\n",
    "\n",
    "    3.1. Dataset vehículos\n",
    "\n",
    "4. Clustering DBSCAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrantes del equipo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Alejandro Cortijo Benito\n",
    "* Alejandro García Mota\n",
    "\n",
    "Este notebook tiene buscamos hacer `clustering` y `tracking` a los vehículos que aparecen en las muestras recogidas con el LiDAR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='imports'></a>Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento de datos\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Visualización de datos\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='dataset'></a>Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset vehículos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos todos los frames del dataset original ordenamos para evitar inconsistencias en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el directorio donde se encuentran los archivos CSV\n",
    "directory = './data/pointclouds/'\n",
    "\n",
    "def extract_timestamp_and_id(filename):\n",
    "    parts = filename.replace('pointcloud_', '').replace('.csv', '').split('_')\n",
    "    timestamp = int(parts[0])  # Primer número (timestamp grande)\n",
    "    identifier = int(parts[1])  # Segundo número (ID más pequeño)\n",
    "    return (timestamp, identifier)\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "\n",
    "for filename in sorted(os.listdir(directory), key=extract_timestamp_and_id):\n",
    "    if filename.endswith('.csv'):  # Comprobar si el archivo es un CSV\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(file_path)  # Cargar el CSV en un DataFrame\n",
    "        dataframes.append(df)  # Añadir el DataFrame a la lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando los conocimientos de `LiDAR_Clustering` procedemos a clusterizar cada frame por separado, hemos decidio usar **DBSCAN** ya que a priori desconocemos el número de de vehículos. Por otro lado, para identificar si los vehículos que salen en escena son los mismos que en el frame anterior vamos a usar la diferencia entre los centroides para computar si el vehivulo del instante `t-1` es el mismo o no. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eculidean_distance(centroid, other):\n",
    "    return np.sqrt((centroid[0] - other[0])**2 + (centroid[1] - other[1])**2 + (centroid[2] - other[2])**2)\n",
    "\n",
    "def get_cluster(last_centroids, center_x, center_y, center_z):\n",
    "    if len(last_centroids) == 0:\n",
    "        last_centroids[0] = [center_x, center_y, center_z]\n",
    "        return 0\n",
    "    \n",
    "    max_distance = 4\n",
    "    distances = {cluster: calculate_eculidean_distance([center_x, center_y, center_z], centroid)\n",
    "                 for cluster, centroid in last_centroids.items()}\n",
    "    \n",
    "    closest_cluster = min(distances, key=distances.get)\n",
    "    if distances[closest_cluster] < max_distance:\n",
    "        last_centroids[closest_cluster] = [center_x, center_y, center_z]\n",
    "        return closest_cluster\n",
    "    \n",
    "    new_cluster_id = max(last_centroids.keys()) + 1\n",
    "    last_centroids[new_cluster_id] = [center_x, center_y, center_z]\n",
    "    return new_cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/369 [00:13<26:45,  4.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 128\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Update layout\u001b[39;00m\n\u001b[0;32m    114\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(\n\u001b[0;32m    115\u001b[0m     scene\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    116\u001b[0m         xaxis_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m     legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLegend\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Improve legend title\u001b[39;00m\n\u001b[0;32m    126\u001b[0m )\n\u001b[1;32m--> 128\u001b[0m fig\u001b[38;5;241m.\u001b[39mwrite_image(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\alexg\\miniconda3\\lib\\site-packages\\plotly\\basedatatypes.py:3835\u001b[0m, in \u001b[0;36mBaseFigure.write_image\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3776\u001b[0m \u001b[38;5;124;03mConvert a figure to a static image and write it to a file or writeable\u001b[39;00m\n\u001b[0;32m   3777\u001b[0m \u001b[38;5;124;03mobject\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3831\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[0;32m   3832\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3833\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[1;32m-> 3835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pio\u001b[38;5;241m.\u001b[39mwrite_image(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alexg\\miniconda3\\lib\\site-packages\\plotly\\io\\_kaleido.py:266\u001b[0m, in \u001b[0;36mwrite_image\u001b[1;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    251\u001b[0m                 \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03mCannot infer image type from output path '{file}'.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 )\n\u001b[0;32m    261\u001b[0m             )\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;66;03m# Request image\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;66;03m# -------------\u001b[39;00m\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;66;03m# Do this first so we don't create a file if image conversion fails\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     img_data \u001b[38;5;241m=\u001b[39m \u001b[43mto_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;66;03m# Open file\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# ---------\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;66;03m# We previously failed to make sense of `file` as a pathlib object.\u001b[39;00m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;66;03m# Attempt to write to `file` as an open file descriptor.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexg\\miniconda3\\lib\\site-packages\\plotly\\io\\_kaleido.py:143\u001b[0m, in \u001b[0;36mto_image\u001b[1;34m(fig, format, width, height, scale, validate, engine)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Validate figure\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# ---------------\u001b[39;00m\n\u001b[0;32m    142\u001b[0m fig_dict \u001b[38;5;241m=\u001b[39m validate_coerce_fig_to_dict(fig, validate)\n\u001b[1;32m--> 143\u001b[0m img_bytes \u001b[38;5;241m=\u001b[39m \u001b[43mscope\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img_bytes\n",
      "File \u001b[1;32mc:\\Users\\alexg\\miniconda3\\lib\\site-packages\\kaleido\\scopes\\plotly.py:103\u001b[0m, in \u001b[0;36mPlotlyScope.transform\u001b[1;34m(self, figure, format, width, height, scale)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid format \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{original_format}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    Supported formats: \u001b[39m\u001b[38;5;132;01m{supported_formats_str}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Transform in using _perform_transform rather than superclass so we can access the full\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# response dict, including error codes.\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Check for export error, later can customize error messages for plotly Python users\u001b[39;00m\n\u001b[0;32m    108\u001b[0m code \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\alexg\\miniconda3\\lib\\site-packages\\kaleido\\scopes\\base.py:304\u001b[0m, in \u001b[0;36mBaseScope._perform_transform\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proc\u001b[38;5;241m.\u001b[39mstdin\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proc\u001b[38;5;241m.\u001b[39mstdin\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m--> 304\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_proc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m response_string \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response_string:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "centroids = []\n",
    "last_centroids = {}\n",
    "output_dir = 'frames'  # Carpeta para guardar las imágenes\n",
    "os.makedirs(output_dir, exist_ok=True)  # Crea el directorio si no existe\n",
    "\n",
    "for i, frame in enumerate(tqdm(dataframes)):\n",
    "    X = frame[['x', 'y', 'z']]\n",
    "\n",
    "    dbscan = DBSCAN(eps=3, min_samples=23, n_jobs=-1)\n",
    "\n",
    "    y_dbscan = dbscan.fit_predict(X)\n",
    "\n",
    "    df_clustered = X.copy()\n",
    "    df_clustered['cluster'] = y_dbscan\n",
    "\n",
    "    # Delete noise\n",
    "    df_clustered = df_clustered[df_clustered['cluster'] != -1]\n",
    "\n",
    "    fig = px.scatter(df_clustered, x='x', y='y', color='cluster')\n",
    "\n",
    "    df_result = pd.DataFrame()\n",
    "    df_result['x'] = df_clustered['x']\n",
    "    df_result['y'] = df_clustered['y']\n",
    "    df_result['z'] = df_clustered['z']\n",
    "    df_result['cluster'] = df_clustered['cluster']\n",
    "    df_result['clusterId'] = -1\n",
    "\n",
    "    # Calculate bounding boxes for each cluster\n",
    "    bounding_boxes = {}\n",
    "\n",
    "    clusters_count = np.array(y_dbscan).max() + 1\n",
    "    for cluster in range(clusters_count):\n",
    "        cluster_points = df_result[df_result['cluster'] == cluster]\n",
    "        min_x, max_x = cluster_points['x'].min(), cluster_points['x'].max()\n",
    "        min_y, max_y = cluster_points['y'].min(), cluster_points['y'].max()\n",
    "        min_z, max_z = cluster_points['z'].min(), cluster_points['z'].max()\n",
    "\n",
    "        # Calculate the center of the bounding box\n",
    "        center_x = (min_x + max_x) / 2\n",
    "        center_y = (min_y + max_y) / 2\n",
    "        center_z = (min_z + max_z) / 2\n",
    "\n",
    "        clusterId = get_cluster(last_centroids, center_x, center_y, center_z)\n",
    "        centroids.append((clusterId, center_x, center_y, center_z))\n",
    "\n",
    "        df_result.loc[df_result['cluster'] == cluster, 'clusterId'] = clusterId\n",
    "        bounding_boxes[clusterId] = {\n",
    "            'min_x': min_x, 'max_x': max_x,\n",
    "            'min_y': min_y, 'max_y': max_y,\n",
    "            'min_z': min_z, 'max_z': max_z\n",
    "        }\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add original data points\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=df_result['x'],\n",
    "        y=df_result['y'],\n",
    "        z=df_result['z'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            color=df_result['clusterId'],\n",
    "            colorscale='Viridis',\n",
    "            cmin=0,\n",
    "            cmax=10,\n",
    "            opacity=0.5\n",
    "        ),\n",
    "        name='Data Points'  # Add a name for the legend\n",
    "    ))\n",
    "\n",
    "    # Add bounding boxes\n",
    "    for cluster, bbox in bounding_boxes.items():\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[bbox['min_x'], bbox['max_x'], bbox['max_x'], bbox['min_x'], bbox['min_x'], bbox['min_x'], bbox['max_x'], bbox['max_x'], bbox['min_x'], bbox['min_x'], bbox['max_x'], bbox['max_x'], bbox['max_x'], bbox['max_x'], bbox['min_x'], bbox['min_x'], bbox['min_x']],\n",
    "            y=[bbox['min_y'], bbox['min_y'], bbox['max_y'], bbox['max_y'], bbox['min_y'], bbox['min_y'], bbox['min_y'], bbox['max_y'], bbox['max_y'], bbox['max_y'], bbox['max_y'], bbox['max_y'], bbox['min_y'], bbox['min_y'], bbox['min_y'], bbox['min_y'], bbox['max_y']],\n",
    "            z=[bbox['min_z'], bbox['min_z'], bbox['min_z'], bbox['min_z'], bbox['min_z'], bbox['max_z'], bbox['max_z'], bbox['max_z'], bbox['max_z'], bbox['min_z'], bbox['min_z'], bbox['max_z'], bbox['max_z'], bbox['min_z'], bbox['min_z'], bbox['max_z'], bbox['max_z']],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', width=3),  # Increase line width\n",
    "            name=f'Vehiculo {cluster}'  # Improved naming\n",
    "        ))\n",
    "\n",
    "    # Add centroids to the plot\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[bbox['min_x'] + (bbox['max_x'] - bbox['min_x']) / 2 for bbox in bounding_boxes.values()],\n",
    "        y=[bbox['min_y'] + (bbox['max_y'] - bbox['min_y']) / 2 for bbox in bounding_boxes.values()],\n",
    "        z=[bbox['min_z'] + (bbox['max_z'] - bbox['min_z']) / 2 for bbox in bounding_boxes.values()],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color='red',\n",
    "            symbol='x'\n",
    "        ),\n",
    "        name='Centroids'\n",
    "    ))\n",
    "\n",
    "\n",
    "    # Draw lines connecting centroids of each cluster with different colors\n",
    "    colors = px.colors.qualitative.Dark24\n",
    "    for cluster_id, centroid in last_centroids.items():\n",
    "        cluster_centroids = [c for c in centroids if c[0] == cluster_id]\n",
    "        if len(cluster_centroids) > 1:\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=[c[1] for c in cluster_centroids],\n",
    "                y=[c[2] for c in cluster_centroids],\n",
    "                z=[c[3] for c in cluster_centroids],\n",
    "                mode='lines',\n",
    "                line=dict(color=colors[cluster_id % len(colors)], width=2),\n",
    "                name=f'Cluster {cluster_id} Path',\n",
    "                showlegend=False\n",
    "            ))\n",
    "\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='X',\n",
    "            yaxis_title='Y',\n",
    "            zaxis_title='Z',\n",
    "            aspectmode='data',\n",
    "            camera=dict(\n",
    "                eye=dict(x=5, y=3, z=4)  # Adjust camera angle\n",
    "            )\n",
    "        ),\n",
    "        title='Carretera',\n",
    "        legend=dict(title='Legend')  # Improve legend title\n",
    "    )\n",
    "\n",
    "    fig.write_image(os.path.join(output_dir, f'frame_{i}.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos todos los frames computados procedemos a unificarlos en un único video `tracking.mp4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking.mp4 creado con éxito.\n"
     ]
    }
   ],
   "source": [
    "image_folder = './frames/'   # Outputs celda anterior (tracking)\n",
    "video_name = 'tracking.mp4'  # Nombre del video de salida\n",
    "\n",
    "# Función para extraer el número de las imágenes\n",
    "def extract_frame_number(filename):\n",
    "    return int(filename.replace('frame_', '').replace('.png', '').replace('.jpg', ''))\n",
    "\n",
    "# Obtener todas las imágenes de la carpeta\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\") or img.endswith(\".png\")]\n",
    "\n",
    "# Ordenar las imágenes por el número extraído\n",
    "images = sorted(images, key=extract_frame_number)\n",
    "\n",
    "# Leer la primera imagen para obtener las dimensiones\n",
    "first_image = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "\n",
    "# Ajustar la resolución\n",
    "desired_width, desired_height = 640, 480\n",
    "first_image_resized = cv2.resize(first_image, (desired_width, desired_height))\n",
    "height, width, layers = first_image_resized.shape\n",
    "\n",
    "# Definir el codec y crear el objeto VideoWriter con 30 FPS\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec compatible con macOS\n",
    "video = cv2.VideoWriter(video_name, fourcc, 4, (width, height))\n",
    "\n",
    "# Añadir cada imagen al video\n",
    "for image in images:\n",
    "    img = cv2.imread(os.path.join(image_folder, image))\n",
    "    img_resized = cv2.resize(img, (desired_width, desired_height))  # Redimensionar cada imagen\n",
    "    video.write(img_resized)\n",
    "\n",
    "# Liberar el objeto VideoWriter\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(video_name+\" creado con éxito.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
